{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os \n",
    "\n",
    "from config import pwd, uname\n",
    "\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy import Column, Integer, String, Float \n",
    "from sqlalchemy import desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caDataSet = os.path.join('..','DataSets','CA Weed Data.csv')\n",
    "cenDataSet = os.path.join('..','DataSets','Census Data.csv')\n",
    "coDataSet = os.path.join('..','DataSets','CO Weed Data.csv')\n",
    "massDataSet = os.path.join('..','DataSets','Mass Weed Data.csv')\n",
    "stateDataSet = os.path.join('..','DataSets','State Names and Abbr.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Database Connections and Get Tables Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create engine to postgres db\n",
    "postgres = f'postgresql://{uname}:{pwd}@localhost:5432/etl_project'  #path to local db\n",
    "\n",
    "engine = create_engine(postgres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "base = automap_base()\n",
    "\n",
    "# reflect the tables\n",
    "base.prepare(engine, reflect=True)\n",
    "\n",
    "# View all of the classes that automap found\n",
    "base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "# adding these for fun and for sanity checks\n",
    "\n",
    "caRaw = base.classes.ca_raw\n",
    "coRaw = base.classes.co_raw\n",
    "massRaw = base.classes.mass_raw\n",
    "states = base.classes.states\n",
    "sales = base.classes.sales_by_qtr\n",
    "census = base.classes.census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dataframes\n",
    "massRawDF = pd.read_csv(massDataSet) \n",
    "cenRawDF = pd.read_csv(cenDataSet)\n",
    "stateDF = pd.read_csv(stateDataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massRawDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Explore and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cenRawDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cenRawDF.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we do not need\n",
    "cenNew = cenRawDF\n",
    "cenNew = cenNew.drop({'SUMLEV' , 'REGION' , 'DIVISION' , 'CENSUS2010POP' , 'ESTIMATESBASE2010' , 'POPESTIMATE2010' , 'POPESTIMATE2011' , 'POPESTIMATE2012' , 'POPESTIMATE2013' , 'POPESTIMATE2014' , \n",
    "                         'POPESTIMATE2015' , 'POPESTIMATE2016' , 'POPESTIMATE2017' , 'NPOPCHG_2010' , 'NPOPCHG_2011' , 'NPOPCHG_2012' , 'NPOPCHG_2013' , 'NPOPCHG_2014' , 'NPOPCHG_2015' , 'NPOPCHG_2016' , \n",
    "                         'NPOPCHG_2017' , 'NPOPCHG_2018' , 'NPOPCHG_2019' , 'NPOPCHG_2020' , 'BIRTHS2010' , 'BIRTHS2011' , 'BIRTHS2012' , 'BIRTHS2013' , 'BIRTHS2014' , 'BIRTHS2015' , 'BIRTHS2016' , 'BIRTHS2017' , \n",
    "                          'BIRTHS2018' , 'BIRTHS2019' , 'BIRTHS2020' , 'DEATHS2010' , 'DEATHS2011' , 'DEATHS2012' , 'DEATHS2013' , 'DEATHS2014' , 'DEATHS2015' , 'DEATHS2016' , 'DEATHS2017' , 'DEATHS2018' , 'DEATHS2019' , \n",
    "                          'DEATHS2020' , 'NATURALINC2010' , 'NATURALINC2011' , 'NATURALINC2012' ,  'NATURALINC2013' ,  'NATURALINC2014' ,  'NATURALINC2015' ,  'NATURALINC2016' ,  'NATURALINC2017' ,  'NATURALINC2018' , \n",
    "                          'NATURALINC2019' ,  'NATURALINC2020' , 'INTERNATIONALMIG2010' , 'INTERNATIONALMIG2011' , 'INTERNATIONALMIG2012' , 'INTERNATIONALMIG2013' , 'INTERNATIONALMIG2014' , 'INTERNATIONALMIG2015' , \n",
    "                         'INTERNATIONALMIG2016' , 'INTERNATIONALMIG2017' , 'INTERNATIONALMIG2018' , 'INTERNATIONALMIG2019' , 'INTERNATIONALMIG2020' , 'DOMESTICMIG2010' , 'DOMESTICMIG2011' , 'DOMESTICMIG2012' , 'DOMESTICMIG2013' , \n",
    "                         'DOMESTICMIG2014' , 'DOMESTICMIG2015' , 'DOMESTICMIG2016' , 'DOMESTICMIG2017' , 'DOMESTICMIG2018' , 'DOMESTICMIG2019' , 'DOMESTICMIG2020' , 'NETMIG2010' , 'NETMIG2011' , 'NETMIG2012' , 'NETMIG2013' ,\n",
    "                         'NETMIG2014' , 'NETMIG2015' , 'NETMIG2016' , 'NETMIG2017' , 'NETMIG2018' , 'NETMIG2019' , 'NETMIG2020' , 'RESIDUAL2010' ,  'RESIDUAL2011' , 'RESIDUAL2012' , 'RESIDUAL2013' , 'RESIDUAL2014' , \n",
    "                         'RESIDUAL2015' , 'RESIDUAL2016' , 'RESIDUAL2017' , 'RESIDUAL2018' , 'RESIDUAL2019' , 'RESIDUAL2020' ,  'RBIRTH2011' , 'RBIRTH2012' , 'RBIRTH2013' , 'RBIRTH2014' , 'RBIRTH2015' , 'RBIRTH2016' , 'RBIRTH2017' , \n",
    "                         'RBIRTH2018' ,  'RBIRTH2019' , 'RBIRTH2020' , 'RDEATH2011' ,  'RDEATH2012' , 'RDEATH2013' , 'RDEATH2014' , 'RDEATH2015' , 'RDEATH2016' , 'RDEATH2017' , 'RDEATH2018' , 'RDEATH2019' , 'RDEATH2020' , \n",
    "                         'RNATURALINC2011' , 'RNATURALINC2012' , 'RNATURALINC2013' , 'RNATURALINC2014' ,  'RNATURALINC2015' ,  'RNATURALINC2016' , 'RNATURALINC2017' , 'RNATURALINC2018' , 'RNATURALINC2019' , 'RNATURALINC2020' ,\n",
    "                         'RINTERNATIONALMIG2011' , 'RINTERNATIONALMIG2012' , 'RINTERNATIONALMIG2013' , 'RINTERNATIONALMIG2014' , 'RINTERNATIONALMIG2015' , 'RINTERNATIONALMIG2016' , 'RINTERNATIONALMIG2017' , 'RINTERNATIONALMIG2018' ,\n",
    "                         'RINTERNATIONALMIG2019' , 'RINTERNATIONALMIG2020' , 'RDOMESTICMIG2011' ,  'RDOMESTICMIG2012' , 'RDOMESTICMIG2013' ,  'RDOMESTICMIG2014' , 'RDOMESTICMIG2015' , 'RDOMESTICMIG2016' , 'RDOMESTICMIG2017' ,\n",
    "                         'RDOMESTICMIG2018' , 'RDOMESTICMIG2019' , 'RDOMESTICMIG2020' , 'RNETMIG2011' , 'RNETMIG2012' , 'RNETMIG2013' , 'RNETMIG2014' , 'RNETMIG2015' , 'RNETMIG2016' , 'RNETMIG2017' , 'RNETMIG2018' , 'RNETMIG2019' , \n",
    "                         'RNETMIG2020'},1)\n",
    "                    \n",
    "\n",
    "cenNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Regional Rows, US row, and Puerto Rico row\n",
    "cenNew = cenNew.drop([ cenNew.index[0] , cenNew.index[1] , cenNew.index[2] , cenNew.index[3] , cenNew.index[4] , cenNew.index[56] ])\n",
    "cenNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match the other tables, and add in a total population column\n",
    "cenNew = cenNew.rename(columns = {'NAME' : 'StateDescName' , 'POPESTIMATE2018' : '2018Pop' , 'POPESTIMATE2019' : '2019Pop' , 'POPESTIMATE2020' : '2020Pop' })\n",
    "cenNew['TotalPop'] = cenNew['2018Pop'] + cenNew['2019Pop'] + cenNew['2020Pop']\n",
    "cenNew = cenNew.drop('STATE' ,1)\n",
    "cenNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-set index\n",
    "cenNew.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cenNew[\"StateID\"] = \"\"\n",
    "cenNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This confirms that both DF are in same order\n",
    "cenNew[\"StateNameMatch\"] = np.where(cenNew['StateDescName'] == stateDF['StateDescName'], 'True' , 'False')\n",
    "cenNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that you know both DFs match row per row, assign StateID for census from StateID for states\n",
    "cenNew[\"StateID\"] = cenNew[\"StateID\"]\n",
    "cenNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the StatesNameMatch\n",
    "cenNew = cenNew.drop('StateNameMatch' ,1)\n",
    "cenNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in column for CensusID\n",
    "CensusID = 0\n",
    "cenNew.insert(CensusID, \"CensusID\", value = range(len(cenNew)))\n",
    "cenNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-org so that columns in same order as SQL table\n",
    "cenNew = cenNew[[\"CensusID\" , \"StateID\" , \"2018Pop\" , \"2019Pop\" , \"2020Pop\", \"TotalPop\"]]\n",
    "cenNew.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateDF=stateDF.drop('Abbrev', 1)\n",
    "stateDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateDF = stateDF.rename(columns = {'State' : 'StateDescName' , 'Code' : 'StateAbbrev'})\n",
    "stateDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StateID = 0 \n",
    "stateDF.insert(StateID, \"StateID\", value = range(len(state_name_df)))\n",
    "stateDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRUNCATE THE TABLE\n",
    "connection = engine.connect()\n",
    "\n",
    "connection.execute( '''TRUNCATE TABLE sales_by_qtr CASCADE''')\n",
    "connection.execute( '''TRUNCATE TABLE census''' )\n",
    "connection.execute( '''TRUNCATE TABLE mass_raw''')\n",
    "connection.execute( '''TRUNCATE TABLE census_raw''' )\n",
    "connection.execute( '''TRUNCATE TABLE states CASCADE''' )\n",
    "\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cenRawDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massRawDF.to_sql('mass_raw', engine, if_exists='append', index=False)\n",
    "cenRawDF.to_sql('census_raw', engine, if_exists='append', index=False)\n",
    "stateDF.to_sql('states',engine, if_exists='append',index=False)\n",
    "census_df.to_sql('census',engine, if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check mass raw \n",
    "session.query(massRaw).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check census raw\n",
    "engine.execute('select count(*) from census_raw').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check states raw\n",
    "session.query(states).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check states raw\n",
    "session.query(census).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
